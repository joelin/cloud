# 云感知应用架构

翻译：**linxuhua:** (hualee215 AT gmail.com)

原文：[architecting_cloud_aware_applications](https://opendatacenteralliance.org/wp-content/uploads/architecting_cloud_aware_applications.pdf)

## 应用程序架构演进历程
应用程序体系结构跟随计算机硬件、 网络和设备从个人电脑到智能手机同步发展至今。云计算作为最新的进化力量，正在改变应用程序体系结构。要了解云计算正在怎样改变应用程序体系架构，思考在常规非云环境应用是如何架构。
### 多层应用架构
比如典型的三层架构由展示层、中间层、数据层三层构建
- 展示层提供用户访问接口
- 中间层接受用户请求并执行应用业务逻辑
- 数据层提供数据存储服务

比如典型的邮件服务器架构，展示层使用outlook类似的客户端，中间层消息服务器ExchangeServer，后端的消息存储数据层；中间层通过应用协议(IMAP)提供api服务给客户端调用，中间层往往会与多个后端服务存在接口，比如邮件系统中，中间层会与用户体系的目录服务、消息存储服务、消息传输代理等有接口。

![muti-tier](muti-tier architecture.png)

三层架构词条：解释略

### 虚拟环境中的多层应用架构
随着数据中心虚拟化技术的应用，越来越多的应用部署在虚拟化环境中，这样可以节省更多的成本和资源调配的时间。
对于应用程序来说，虚拟化环境几乎都是同质化的，包含应用的构造方法、配置静态数据等。由于虚拟环境可以根据需求创建和配置新的应用组件的实例，配合虚拟感知的负载技术、虚拟IP技术使扩展变得更容易，而且每层的独立扩展相对于其它层来说都是透明的。


### 云应用架构
在云环境开发应用时，开发人员不一定非的改造应用的架构来适应云环境，开发人员照样可以把应用部署在云环境中，比如使用P2V方法，把物理机的应用原样迁移到虚拟机中，但是这样会妨碍应用使用云的特殊功能。比如原来的多层部署模式，耦合了依赖层的相关信息(服务信息、IP地址、web相关配置等)，这样就无法做到自动化扩展到多个虚机或私有、公共云的多个实例。如果要有效地利用云的功能，那么应用在设计架构时，就要基于云的思想和特性去考虑应用的架构，包含弹性、自助服务、多租户等等。例如下图展示的传统多层和云应用比较。

![muti vs cloud](muti-tier vs cloud.png)

### 云应用架构原则
本节概述了云计算的应用程序体系结构的根本原则，表 1 列出了架构原则:它影响应用程序自身是如何组织、编码、确定最终用户怎样与之交互；表 3 总结了运维准则：它考虑了整个系统，包括如何部署应用程序的工作原理和操作，以及其他系统组件如何与之进行交互。

这些原则一般适用基于特定应用程序的上下文，并可能随着时间的推移逐步实施。在开发云知道应用程序时，表中优先级为高的原则应该优先考虑，低优先级的原则在云感知的架构中并不显得那么重要。

表 1. 架构原则

| 序号 | 原则 |描述|优先级
|--------|--------|---------|----------|
| 1|故障弹性 |弹性设计到应用程序中，而不是事后对应用的包装。这样对云计算基础设施的故障能够不中断服务的流畅处理|高|
| 2|延迟弹性 |优雅延迟的应用由于超时和中断的应用|高|
| 3|安全性|应用程序是基于生命周期的安全标准，包括内置的安全性。<br>落地的数据和传输的数据是加密的，API有认证和授权的保护|高|
| 4|位置无关|应用应动态的发现服务，而不是依赖硬编码|高|
| 5|弹性可伸缩|应用程序响应需求的级别，伸缩的需求，以及云自身特性支持|高|
| 6|SOA/组件化|应用的消费端和web服务的apis暴露提供端能够做到运行时可发现，架构结合轻量级、无状态的可扩展组件设计原则|高|
| 7|可管理性|应用可被检测，并能暴漏其度量数据和管理接口|中|
| 8|基础设施无关|应用程序不应该有任何的基础设施假设条件，应建立在抽象层的操作系统、文件系统、数据库等等之上|中|
| 9|租户定义|每个应用都应该定义一个成熟的单租户隔离和多租户共享的模式|中|
| 10|最终用户的自助服务|用户应该能够自助注册，并使用自助服务使用应用，而不是通过IT服务申请|中|
| 11|带宽感知|应设计尽量减少带宽的api和应用协议|低|
| 12|资源和成本的消耗感知|应设计尽量减少带宽、 CPU、 存储消费量和输入/输出请求的应用架构来减少费用支出|低|

接下来详细介绍云计算的应用程序的架构原则。这些原则指导应用程序是如何组织和编码，并确定最终用户如何与它进行交互。

#### 故障弹性

在大规模可伸缩的云计算环境中，应用程序很可能会被某些故障中断。潜在的故障包括计算的硬件故障、网络或存储物理设备故障、在应用程序组件或云服务软件故障、网络故障导致应用组件的迟钝或瞬间断链问题。为了抵御这些类型的故障，应用程序的架构必须能够无需人工干预且能够无缝处理这些故障，无论是通过用降级处理性能水平还是优雅功能降级策略。


#### and so on

### 云应用设计模式

此章节详细描述了特定的可应用于云应用有效云服务和现有模式的设计模式

#### 熔断器模式

熔断器模式被Michael Nygard提出，被NetFlix作为云服务的组成部分应用后得到长足发展。在这个设计模式里，熔断器插入请求组件和处理请求的组件之间，好像一个电路开关一样，熔断器有两个状态：打开或闭合。当熔断器闭合时，线路处于连通状态，请求可以顺畅的被转接到正常的处理组件。在一个软件版本中，请求通过被组件正常处理，熔断器打开就意味着线路出现故障，请求无法转发到正常处理的组件，意味着链路故障。熔断器的作用是检测线路和切换线路到安全的回退状态，如何决定一个熔断器的切换，其触发准则如下：
 * 请求的远端服务超时
 * 远端服务的请求队列已满，意味着该远程服务无法处理其它请求

 这些导致服务错误的共同因素到达一定阀值时，会处理该服务的熔断器切换为打开状态。
 一旦熔断器为打开状态，组件切换到备用状态。有三个备用策略：
 * 失败透明策略
   通过fallback的api方法生成一个定制的响应，例如： 返回一个cache的值或默认值。
 * 无感知的失败
   当服务调用时，如果返回值不是调用服务的关键，可以返回一个空值而不是中断服务调用
 * 快速失败处理
   如果没有敏感数据和调用服务的业务数据时，生成一个5XX的错误是有必要的；同时要求调用的服务使用对用户有意义的方式来处理错误

 理想情况下，一个组件的失败是透明的，但这并不总是可行的。
 需要注意的是，熔断器行为应区别于条件式的响应处理（“如果超时，则返回500”）:
  - 熔断器的切换往往是一段时间内的滚动窗口行为的结果，而不是单一的失败
  - 熔断器的切换和fallback行为一直延续到其被重置
  - 熔断器的状态从组件外部应该是可见的，以便其提在fallback模式下对工具提供可见性
  - 熔断器是从组件外控制的

 在Netflix的实现中，熔断器周期性的允许请求传递到处理的组件，如果处理成功，则熔断器复位，所有的请求将被允许传递到处理的组件。
 下图为熔断器处理逻辑

 ![熔断器处理逻辑](circuit-logic.png)

 Netflix在仪表盘里显示熔断器控制的相同数据的状态，为组件状态和信息提供了一个统一的视图而不是针对组件显示常规的错误码信息。
 下图为仪表盘示例

 ![仪表盘示例](circuit-view.png)

##### 熔断器设计模式
  以下是熔断器设计模式里的重要几点([参考]( http://techblog.netflix.com/2012/02/faulttolerance-in-high-volume.html))：

  * 效益
    - 提高故障恢复的能力
    - 使组件故障可见
  * 在哪里使用
    - 为了消除网络延迟或虚拟机实例的故障
    - 防止级连错误蔓延和处理上游复杂的错误信息(故障透明、故障无感知)

#### 请求队列
   请求队列设计模式包含应用程序组件将请求按一个或多个队列排队处理。这些请求被可用的计算节点处理。队列作为请求方与处理服务方的缓冲以避免过载导致服务失败或处理超时。这种模式是生产者与消费者和基于队列的负载调配模式的变种。
    而不是发出所有接收的请求到一个最终端消费，通过队列请求可以负载给最终的消费端盒整个计算集群。如果某个计算节点故障，其它的工作节点将继续处理队列中的请求，这为云感知应用的高可用性提供了容错工作。
    在服务器中运行时，当管理控制服务消耗的资源使用情况时，队列还可以作为一种节流或阻止请求的机制。比如每秒从给定客户端发过来的多个请求数超过一个给定的数后执行拒绝的操作。性能计数器可以在请求排队前就处理。如果客户端的请求超过了云应用的配置阀值，它们将会被阻塞。 阻塞之后，客户端会接受一个429的http错误（太多的请求）和 重试时间。
    图5 微软的队列示例
    ![微软的队列示例](queue.png)

##### 请求队列设计模式
   以下是请求队列设计模式里的重要几点([参考](http://www.rabbitmq.com/tutorials/amqp-concepts.html))

   * 效益
     - 提高容错性以确保高可用
     - 提高高并发的APIs性能
   * 在哪里使用
     - 管理应用的故障切换
     - 减少高并发请求APIs负载
     - 通过节流应用备用策略做到自动伸缩

#### 请求打包
   请求打包模式是API请求对应于API响应缓存。在这种设计模式中，对于高并发的API方法的多个相邻的请求被打包为一个请求。例如，显示视频的web应用程序会从视频服务端获取视频的元数据，比如视频长度。在一个常规的应用中，每个用户在访问这个页面时都将导致发起视频元数据的单独请求，如果使用请求打包，那么在给定的时间间隔，多个请求将会打包成一个请求。这不仅降低了API服务端的网络带宽和负载，还使其能够扩展支持大并发的用户请求。
   对于打包请求，在代理的APIs的服务端定一个窗口时间来排队请求，比如:10毫秒.这样队列会周期性的把周期内的请求打包为一个请求发送给APIs服务端处理，然后获取到响应后分发响应到每一个请求者。当然这种只有在非常高并发请求时是合适的。如果在一个窗口时间内只有一个请求，这反倒因为引入了等待时间从而影响应用的性能，一般性来说，窗口的时间应设置为请求的延迟的2倍，比如5ms延迟，设置10ms的窗口时间。
   下图为请求打包的示例
   ![请求打包的示例](request-collapse.png)

#### 对象改变通知

   按惯例，在一个紧密耦合架构的系统内部各组件之间存在固定的关系，比如某个系统的A和B组件，有这么一个依赖关系，B依赖于A通知它改变其管理的对象。A也知道只有一个B的实例和它的位置，如果B由于某些原因不可见了，A就无法通知到B以及必需要在某些场景下执行的处理机制。A和B之间的依赖就成了单点故障。

   分布式系统有许多这样的依赖，每一个都会降低整个系统的弹性机制，对于这个问题的解决方案就是在架构中引入冗余，把一对一的依赖变成一对多的依赖关系。例如，代替依赖于单一B的，可以把B改变为多示例，这样任一B示例的故障对A的影响都可以忽略不计。
   对象改变通知的设计模式，也被称之为观察者模式，使得这种类型的事件能够被处理，并可以用于提高弹性。

   这种模式中，通知组件(A)实现"可观察"接口、使"观察员"(B)向被观察的组件注册感兴趣的变化。当某些变化在可观察范围时，它将变化情况通知所有观察者。观察员会从通知消息中接收(推模式)变化的详情，或者查询可观察接口或去事件详细(拉模式)。
   在云环境中，这种模式是应用可以弹性伸缩。由于组件不再是紧耦合，额外的示例可以动态地增加系统的处理能力，用于并行计算或I/O密集型任务特别有价值。例如，Netflix的视频必需转换为多个版本，比如不同的设备的分辨率、比特率、不同的带宽等等。使用对象通知模式，当一个新的视频被上传到存储服务器时，代理检测到存储服务的变化，并启动一组转码工作者来分别处理不同的分辨率和带宽需求的转码工作。转码完成后关闭它们。
##### 对象变更通知模式

以下是对象改变通知设计模式里的重要几点([参考](https://developers.google.com/storage/docs/object-change-notification))

  * 效益
    - 改进故障恢复能力
    - 增加扩展能力
    - 提高资源有效利用率
  * 哪里使用
    - 并行计算密集型
    - 消除单点故障
    - 降低系统的组件之间耦合度

#### 服务发现

  在分布式系统中，组件于组件之间进行服务调用。发起请求时，组件需要知道这个服务的地址。在传统的多层应用程序中，服务的主机名存储在一个配置文件中，然后使用DNS来查找真实的IP。为了伸缩性支持，IP地址可以参考VIP方案来做负载均衡的部署，对应后端多个服务实例。
  而云环境是高度动态化的，服务的实例和应用的组件会持续不断的加入或退出。对于传统的负载伸缩模型来说，当虚拟机实例、存储、网络的故障发生时，基于DNS的负载均衡模式会把请求重定向到不存在或可预见失败的实例上。解决方案是云服务发现机制，让请求发生时间只有健康的服务实例提供服务，这样的服务发现机制具备如下功能：
   * 为组件提供一种引导请求到可用实例的方法
   * 支持服务实例的动态注册和注销
   * 让每个组件的状态是可管理的
  Netflix实现的服务注册框架"Eureka"拥有这些功能， 以下是它的设计逻辑。
  ![Eureka](eureka.png)

##### 服务发现模式

以下是服务发现设计模式里的重要几点([参考](https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance))

  * 效益
    - 改进故障恢复能力
    - 简化基础设施管理
    - 简化动态环境中应用程序的开发
  * 哪里使用
    - 在自动伸缩环境中使用

#### 微服务

  在微服务架构里，一个完整的单体服务会被按功能划分为细粒度的微服务，每个服务一个功能。例如在电子邮件系统中，把单一的消息存储服务分解为单独的服务(新增、修改、删除、读取消息等)，这样，在阅读邮件的功能里面，就可以服用读取消息的服务来提供支持。微服务架构有如下优点:弹性伸缩、高性能、高可靠性和易于部署。

  微服务可以更好支持弹性的原因：因为系统可以按需要横向扩展某个细粒度的服务。比如邮件系统中，如果读取邮件服务超过写邮件的服务需求时，可以仅增加读取的服务实例来处理请求，相对于单体服务来说，没必要复制整个服务来扩展，可以减少资源的浪费。

  微服务可以简化软件更新的开发和部署，开发人员用户一个完整服务的控制权，他可以开发和发布一个独立的服务更新。比如读取邮件的服务开发者，如果改进了读取逻辑并加入缓存机制，它并不需要依赖于其它服务，也不必与他们进行集成就可以单独发布到生产。这样各项功能的开发可以并行进行，开发人员可以根据自己的时间表来安排工作和进度。

  "部署云应用的最好方式是什么？如何编写可重用的代码？怎样才能够快速应对业务的变化？答案似乎就是微服务架构。通过创建单一功能的微服务，并把它做到足够好--减少开销和增加扩展性。这些我们称之为弹性。开发者开发成百上千的小程序，消除深层次的软件共生性(Jim Weirich[Connascence-共生性是被Meilir Page-Jones提出，Jim Weirich在其演讲中有提到它])，结合开发人员的可以重复测试和重构策略可以构建快速响应、可伸缩的云应用
  -- Michael Forhan, AppFirst blog: “Lessons from Distill”  

  Netflix公司已经开发出一种方法来部署微服务更新。采用灰度发布模式，他们先部署一个新版的服务实例而不是全部实例，使用这一个实例进行冒烟测试，如果发现问题，则修复它，其影响性可以忽略不计。如果服务运行正常，则可以小批量的部署新版本以取代旧的版本。对于小批量的新实例还会被实时监控一段时间(以发现是否由内存泄露等问题)，如果有问题，流量会被重定向到没有更新的旧版本实例，下线新版本实例，并修复问题。如果没有问题，则新实例运行一段时间后，停掉旧版本实例。Netflix公司利用持续部署方案来实现这个过程的自动化，从而加快部署速度，能够快速迭代，减少出错机率。 Netflix公司采用了一种简单的理念：在不影响整体服务的情况下，允许可控的失败和实现快速恢复。

  微服务的另一个好处就是出错后，很容易界定错误的范围，因为故障就在微服务的小范围之内。在生产上这就比较好识别错误是由哪些更新导致，并且谁为此负责。

##### 微服务模式

  以下是微服务设计模式里的重要几点([参考](http://martinfowler.com/articles/microservices.html))

  * 效益
    - 减少部署更新带来的开销
    - 减少服务之间的边界副作用
    - 弹性实现更新容易
    - 快速定位问题
    - 提高开发人员生产力
  * 哪里使用
    - 在大型系统中，需要弹性伸缩和降低成本
    - 消除单点故障
    - 提高处理性能
    - 需要支持频繁更新的重要系统

#### 无状态服务

   无状态服务是说，服务端不会保存客户端的状态。因此，每个请求必须包含服务需要处理请求所需的全部信息，这种设计模式主要为分布式系统设计时带来如下好处
   * 可靠性
     由于客户端可以简单的重试失败的请求，无需重建和管理请求失败前的状态信息。
   * 可扩展性
     无状态服务从以下几点来改进扩展性：一、服务没有状态，任何实例可以处理来自任何客户端的请求。二、可以随着请求的负载的增加动态的扩展实例，而不影响现有的实例。三、服务端不需要保持状态，可以腾出更多的资源来处理客户端的请求，增加了服务的负载能力。
   * 可见性
     从运维角度来看，增加了服务的可见性。因为每次请求都会有完整的请求信息，所以运维人员可以通过代理等方法，比如APIs管理上，使得请求语义有更有好的可见性。
   * 简单化
     由于服务不存在状态，没有必要在并发请求事务期间管理请求数据或者锁，这使得实现无状态服务更容易，
     服务更容易被调试和预测，消除了特殊巧合状态下触发的缺陷。

   无状态服务的缺点是请求的数据会变的更大，由于服务需要处理请求的状态的信息必须由每个请求提供，而不是缓存在服务器上。但是无状态服务带来的效益会远远大于其缺点。

   以下是无状态服务设计模式里的重要几点([参考](http://en.wikipedia.org/wiki/Service_statelessness_principle))

   * 效益
     - 提高可靠性
     - 改进扩展性
     - 提高了监控和请求管理的可见性
     - 易于实现
     - 不易发生巧合状态带来的缺陷
   * 哪里使用
     - 任何需要高可扩展性的分布式系统

#### 配置服务
   传统应用的运行时配置通常存在应用程序包中的一个或多个文件。如果设计为热配置模式，那么可以在运行期间对其进行修改；如果设计不为热配置模式，则需要修改后重启应用或重新触发装载配置文件，这个过程会导致停机时间和额外的管理带来的开销。
   通常情况下，这些配置文件在应用程序内部存储和管理，这导致跨节点部署应用程序时会存在文件的冗余存储，随着集群的不断增大，则会增加这些配置管理的开销。

##### 外部配置存储
   让应用程序的配置文件持久化在提供管理云感知应用配置的中央存储库的外部存储中。把配置信息从本地的应用实例中移出，当应用程序之间共享时提供更容易管理和数据控制。这种外部数据存储方式可以随着部署环境的同步而变化。
   数据库或文件系统可以为读写配置文件提供很大的灵活度，对于敏感信息，比如密码等，可以在持续集成的过程中加载或者在运行时使用环境变量注入模式。
   下图是外部配置存储和应用加载过程
   ![config-load](config-load.png)

##### 运行时热配置
   精心设计的云应用应确保高可用的同时尽量减少停机时间，任何需要应用程序重新部署的配置改变都讲增加停机的时间，运行时热配置使得应用在运行时能够感知配置的变化并自动装载配置。
   为支持运行时热配置，需要应用从代码就妥善考虑怎么处理配置变化的通知事件，通常情况下，还是通过观察者模式完成:应用服务器在集中配置服务中注册，并接收任何配置的变更更新。当一个通知事件被触发时，比如，一个新的配置文件被上传，应用程序会先获取最新的配置，然后下载到本地，然后应用读取配置文件，并装载配置在内存中。

   Apache Zookeeper 是 Apache基金会的一个开源项目，它支持运行时的热配置，它提供管理配置信息、命名、分布式同步、服务分组的集中式服务。它可以提供共享的配置服务，也被称作集群协调应用。

   使用Zookeeper的存储配置信息提供两大好处:
  - 新的节点能够获取如何连接Zookeeper的说明，然后可以下载所有的配置信息，并根据配置信息确定他们在集群中的角色。
  - 应用程序可以订阅配置的变化，在运行时允许通过Zookeeper客户端配置和云感知应用程序群集的修改行为来微调配置信息。在集群上运行Zookeeper的模式被称作"合唱",其共享应用数据的状态，参见下图。这种方式允许分布式进程在云感知应用集群内保持协调。
  ![zk](zk.png)

  以下是配置服务设计模式里的重要几点([参考](http://zookeeper.apache.org))

  * 效益
    - 提供单一的、集中存储的配置管理
    - 减少应用配置管理的开销
    - 减少应用停机时间
    - 提高源码缺陷的可见性
    - 提高开发人员生产力
  * 哪里使用
    - 任何需要配置的分布式系统
    - 需要高可用且停机时间少的应用

#### 授权模式
   在云应用中，网络往往是被安全的，因为它不是应用拥有者所能控制的，这就意味着第三方可以在传输过程中拦截和重定向或者窥探数据。另一个风险是在多租户的云环境或者公共网络中，API服务可以被其它租户访问到。这将导致API会成为拒绝服务的攻击目标、让他人访问私有信息，或者提供一种蓄意破坏服务方式。云应用特别容易受到此类攻击，因为他们是由相互依赖的服务且通过网络进行通信的分布式系统。网络依赖和相互调用的api都将增加程序风险，解决方案是加密通信和用授权机制保护api。

##### API授权
  API授权可以确保只有受信任的API的消费者执行API操作。这种方法可以防止恶意访问服务，且支持多个客户端具有不同的访问权限。例如，一些客户可能被授予只读访问该服务，和其他人可能有读写权限。授权还可以用于通过限制哪些客户端能够访问的API以执行架构限制。例如，数据库API可以与访问权限，以确保客户端使用的优选的数据访问服务进行保护。在这种情况下，数据库API将授予只读到数据访问服务/写访问。授权还可以通过限制客户端访问API的方式实施架构体系约束，例如：数据库的API只授权读写权限给数据访问的服务。

  历来应用使用用户名和密码用于客户端－服务端的身份认证。这个方案有两个主要问题：客户端需要存储用户名和密码在本地，这可能会泄漏这些敏感信息导致此种保护机制非常脆弱。在每个组件内部管理用户名和密码还增加了其复杂性、管理的开销和配置出错的风险。

  OAuth 2.0 标准([RFC6749](http://tools.ietf.org/html/rfc6749)) 通过引入基于令牌的访问控制的概念解决了这些问题。在OAuth中，授权服务颁发令牌给客户端达到授权保护资源的特殊访问权限的目的。

  OAuth 服务控制如下图：
   * 客户端通过授权服务器的身份验证并获取服务的访问令牌（1）
   * 授权服务器验证身份验证凭证，如果有效则返回一个访问令牌(2)
   * 客户端需要在每次服务请求时传递访问令牌（5）
   * 每次请求时，服务通过授权服务器检查令牌的有效性(6)
   * 授权服务器提供权限集与令牌关联的查询服务(7)
   * 服务使用权限检查以确定请求操作是否允许，并有条件的执行完操作，然后返回响应数据给客户端(8)

 请求和响应除了需要传递访问令牌外与常规的web服务标准并没有什么不同。注意，访问令牌处于安全的原因是有有效期的。当它到期时，客户端使用刷新令牌请求获取一个新的访问令牌。

  ![oauth](oauth.png)

  以下是授权设计模式里的重要几点([OAuth 2.0 specification](http://tools.ietf.org/html/rfc6749)，[Practices for Secure Development of
  Cloud Applications](http://www.safecode.org/publications/SAFECode_CSA_Cloud_Final1213.pdf))
  * 效益
    - 提高安全性
    - 提供细粒度的访问控制服务
  * 哪里使用
    - 适用于所有客户端－服务端和服务－服务请求模式

### 评估应用程序的云成熟度
云应用成熟度模型提供简单的方式来评估应用程序，与Richardson成熟度模型评估REST API的成熟度一样。在云环境中成熟度模型可以提出意见实现提高应用程序的故障恢复能力、灵活性和可扩展性。

在表2中，成熟度模型有4个级别，3代表最高水平，0代表应用程序不是云感知应用。

|成熟度级别|描述|
|------|------|
|3级自适应|应用程序可以动态的跨基础实施供应商迁移而中断服务<br> 应用程序随着外界的变化可以适当的伸缩|
|2级抽象|服务是无状态的<br>应用程序对失败的服务无感知，不会受其影响<br> 应用程序对基础设施不敏感，可以运行在任意基础设置中|
|1级松耦合|应用程序由松耦合服务组成<br> 应用程序服务由名字来自动发现<br>应用程序的计算和存储是分开的<br>应用程序依赖一个或多个云服务：计算、存储、网络|
|0级虚拟化|应用程序运行在虚拟化的基础架构中<br>应用程序能够从一个镜像或脚本实例化|

#### 成熟度级别 0: 虚拟化
级别0是最不成熟的级别。此级别应用程序只需运行在虚拟化的计算资源如VM。应用程序从一个保存的镜像活着动态脚本来实例化，比如[puppet](https://puppet.com/),[chef](https://www.chef.io/chef/).此类应用通常是紧耦合的，带有应用程序所有组件之间的显示的依赖。
#### 成熟度级别 1: 松耦合
1级解决了0级松耦合的问题，松散耦合是指组件没有对彼此的依赖，因此，如果一个组件出现故障，其他组件不受影响，应用程序可以继续正常运作。通过启用异步的组件，松耦合还可以很容易的扩展。

#### 成熟度级别 2: 抽象
这个级别介绍可以运行在任何云计算基础架构上的能力，现在面临的挑战是主要的几个云计算平台提供的服务和虚拟机镜像格式是有区别的。这就是限制了其互用性程度，不经修改的应用程序能够跨不同的云提供商运行是罕见的。所以工程师必须云无关的抽象和脚本来使得应用程序可以在任何的虚拟化基础架构上实例化，并提供相同的功能特性。这是重要的额外工作，也是需要注意成本／收益分析的决策。其好处是，应用程序不依赖于特定的供应商的专有接口，不依赖特定的厂商，可以提供运行时的动态服务迁移。

除了基础设施的抽象，在这一级别应用程序应不依赖于特定的服务实例的可用性。因为应用程序使用从网络层重发数据的模式从而与故障的服务之间完全被隔离开。实际上，无论是应用程序还是它的使用者，在应用程序的组件故障时都不应该有任何感知。一种解决方案就是Netflix在亚马逊服务上使用的熔断器设计模式。

最后，由于服务实例可能在任何时候发生故障，当一个服务故障并下线时，必须要有另外的实例起来并且提供服务。所以只有在服务没有任何私有状态、或者存在状态可以被所有服务共享、或者没有任何存储的状态下才能够被实现。

#### 成熟度级别 3: 自适应
此级别表示应用程序已被设计为能够充分利用云环境特性。这一级别的应用程序能够在不中断服务的情况下，无缝的、部分或者全部的从一个云环境迁移到另一个云环境。这就要求它小表现所有前面的成熟度级别。应用程序和服务层迁移的编排职责在于某种叫云"主控程序"的系统，它可以决定何时迁移应用程序以及迁往何处。例如，由于高负载、环境的不稳定或者利用非繁忙时间定价策略，该系统可能选择把应用程序从一个云环境迁移到另外一个。

级别3的应用程序也可以利用云的弹性伸缩能力，当高负载时动态的扩展或者在低活跃期下线部分实例。应用程序可以增加服务实例来水平扩展或者增加虚拟CPUs、内存到已有实例来垂直扩展。这不是应用程序的规则，尽管它需要定义元数据来使得某些代理能够决定使用何种方式来扩展给的服务。

### 运维策略
本节包含云感知应用运维原则的关键点(见表3)。运维原则是指如何部署和运维，其它系统组件如何与之交互。运维策略的焦点为完整系统的整个生命周期内端到端的使用。

Table 3. Operational strategies.

|序号|原则|属性|级别|
|---|---|---|---|
|1|确保冗余|虽然由冗余的节点，但是应用程序也必需设计为能够故障恢复|高|
|2|利用缓存|缓存是用来提高性能、增加弹性伸缩、降低带宽成本|高|
|3|保护API的访问|API端点通过API管理网管保护|高|
|4|分阶段部署|分阶段的更新应用程序的组件以减少部署失败带来的风险|中|
|5|区域或地区的故障应对错误|应用程序的部署应该适应于灾乱性故障，比如地理区域的故障或地区的故障|中|
|6|减少区域间或地区的延迟|应用程序的部署位置选择应以尽量减少带宽为前提|中|
|7|定位外部高带宽的消费者|高带宽的消费者应托管在云的外部，以减少云带宽的使用成本|中|
|8|抽象依赖关系|API的抽象用来防止绑死专有的云服务|低|

## 结论

## 参考

## 附录
